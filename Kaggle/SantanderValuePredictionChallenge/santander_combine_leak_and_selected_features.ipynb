{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b8/Banco_Santander_Logotipo.svg\" width=\"800\"></img>\n",
    "\n",
    "<h1><center><font size=\"6\">Santander Combine Leak Exploatation and Model with Selected Features</font></center></h1>\n",
    "\n",
    "\n",
    "# <a id='0'>Content</a>\n",
    "\n",
    "- <a href='#1'>Introduction</a>  \n",
    "- <a href='#2'>Load packages</a>  \n",
    "- <a href='#3'>Read the data</a>  \n",
    "- <a href='#4'>Exploit the leak</a> \n",
    "- <a href='#5'>Build a model</a>\n",
    "- <a href='#6'>Averaging and submission</a> \n",
    "- <a href='#7'>References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"1\">Introduction</a>  \n",
    "\n",
    "In this Kernel we combine the nd creation of a model with selected features [1][2] with exploatation of the leak (as identified by Giba [3] and developed by Moshin [4])\n",
    "\n",
    "<a href=\"#0\"><font size=\"1\">Go to top</font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"2\">Load packages</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import mode, skew, kurtosis, entropy\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Print all rows and columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "IS_LOCAL = True\n",
    "\n",
    "import os\n",
    "\n",
    "if(IS_LOCAL):\n",
    "    PATH=\"../input/santander-value-prediction-challenge/\"\n",
    "else:\n",
    "    PATH=\"../input/\"\n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"3\">Read the data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH+\"train.csv\")\n",
    "test = pd.read_csv(PATH+\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#0\"><font size=\"1\">Go to top</font></a>\n",
    "\n",
    "# <a id=\"4\">Exploit the leak</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NLAGS = 29 #number of lags for leak calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]\n",
    "y = np.log1p(train[\"target\"]).values\n",
    "cols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1',\n",
    "        '15ace8c9f', 'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9',\n",
    "        'd6bb78916', 'b43a7cfd5', '58232a6fb', '1702b5bf0', '324921c7b',\n",
    "        '62e59a501', '2ec5b290f', '241f0f867', 'fb49e4212', '66ace2992',\n",
    "        'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', '1931ccfdd',\n",
    "        '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a',\n",
    "        '6619d81fc', '1db387535', 'fc99f9426', '91f701ba2', '0572565c2',\n",
    "        '190db8488', 'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_leak(df, cols, lag=0):\n",
    "    \"\"\" To get leak value, we do following:\n",
    "       1. Get string of all values after removing first two time steps\n",
    "       2. For all rows we shift the row by two steps and again make a string\n",
    "       3. Just find rows where string from 2 matches string from 1\n",
    "       4. Get 1st time step of row in 3 (Currently, there is additional condition to only fetch value if we got exactly one match in step 3)\"\"\"\n",
    "    series_str = df[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n",
    "    series_shifted_str = df[cols].shift(lag+2, axis=1)[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n",
    "    target_rows = series_shifted_str.progress_apply(lambda x: np.where(x == series_str)[0])\n",
    "    target_vals = target_rows.apply(lambda x: df.loc[x[0], cols[lag]] if len(x)==1 else 0)\n",
    "    return target_vals\n",
    "\n",
    "def get_all_leak(df, cols=None, nlags=15):\n",
    "    \"\"\"\n",
    "    We just recursively fetch target value for different lags\n",
    "    \"\"\"\n",
    "    df =  df.copy()\n",
    "    for i in range(nlags):\n",
    "        print(\"Processing lag {}\".format(i))\n",
    "        df[\"leaked_target_\"+str(i)] = _get_leak(df, cols, i)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the test **target** column with the mean of train **target** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"target\"] = train[\"target\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying the **get_all_leaks** function, we create a unique dataframe with all selected columns in train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>f190486d6</th>\n",
       "      <th>58e2e02e6</th>\n",
       "      <th>eeb9cd3aa</th>\n",
       "      <th>9fd594eec</th>\n",
       "      <th>6eef030c1</th>\n",
       "      <th>15ace8c9f</th>\n",
       "      <th>fb0f5dbfe</th>\n",
       "      <th>58e056e12</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>024c577b9</th>\n",
       "      <th>d6bb78916</th>\n",
       "      <th>b43a7cfd5</th>\n",
       "      <th>58232a6fb</th>\n",
       "      <th>1702b5bf0</th>\n",
       "      <th>324921c7b</th>\n",
       "      <th>62e59a501</th>\n",
       "      <th>2ec5b290f</th>\n",
       "      <th>241f0f867</th>\n",
       "      <th>fb49e4212</th>\n",
       "      <th>66ace2992</th>\n",
       "      <th>f74e8f13d</th>\n",
       "      <th>5c6487af1</th>\n",
       "      <th>963a49cdc</th>\n",
       "      <th>26fc93eb7</th>\n",
       "      <th>1931ccfdd</th>\n",
       "      <th>703885424</th>\n",
       "      <th>70feb1494</th>\n",
       "      <th>491b9ee45</th>\n",
       "      <th>23310aa6f</th>\n",
       "      <th>e176a204a</th>\n",
       "      <th>6619d81fc</th>\n",
       "      <th>1db387535</th>\n",
       "      <th>fc99f9426</th>\n",
       "      <th>91f701ba2</th>\n",
       "      <th>0572565c2</th>\n",
       "      <th>190db8488</th>\n",
       "      <th>adb64ff71</th>\n",
       "      <th>c47340d97</th>\n",
       "      <th>c5a231d81</th>\n",
       "      <th>0ff32eb98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>1866666.66</td>\n",
       "      <td>12066666.66</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>4100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6050000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>950000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1733333.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13200000.0</td>\n",
       "      <td>3205000.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2850000.00</td>\n",
       "      <td>2225000.0</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3300000.0</td>\n",
       "      <td>2200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5500000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>2000000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37662000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>6700000.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>5400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1180000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      target   f190486d6    58e2e02e6  eeb9cd3aa  9fd594eec  \\\n",
       "0  000d6aaf2  38000000.0  1866666.66  12066666.66   700000.0   600000.0   \n",
       "1  000fbd867    600000.0        0.00   2850000.00  2225000.0  1800000.0   \n",
       "2  0027d6b71  10000000.0        0.00         0.00        0.0        0.0   \n",
       "3  0028cbf45   2000000.0  2000000.00         0.00        0.0        0.0   \n",
       "4  002a68644  14400000.0        0.00         0.00        0.0        0.0   \n",
       "\n",
       "    6eef030c1  15ace8c9f  fb0f5dbfe  58e056e12  20aa07010  024c577b9  \\\n",
       "0    900000.0  4100000.0        0.0        0.0        0.0        0.0   \n",
       "1    800000.0        0.0        0.0  3300000.0  2200000.0        0.0   \n",
       "2         0.0        0.0        0.0  6000000.0        0.0        0.0   \n",
       "3         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4  37662000.0        0.0  4000000.0  6700000.0  2000000.0  5400000.0   \n",
       "\n",
       "   d6bb78916  b43a7cfd5   58232a6fb   1702b5bf0  324921c7b  62e59a501  \\\n",
       "0        0.0        0.0  28000000.0         0.0  6050000.0        0.0   \n",
       "1  2000000.0        0.0         0.0  16000000.0  7000000.0        0.0   \n",
       "2        0.0        0.0         0.0         0.0        0.0        0.0   \n",
       "3        0.0        0.0         0.0         0.0        0.0        0.0   \n",
       "4        0.0        0.0         0.0         0.0        0.0        0.0   \n",
       "\n",
       "   2ec5b290f  241f0f867  fb49e4212  66ace2992   f74e8f13d  5c6487af1  \\\n",
       "0        0.0   950000.0        0.0        0.0  1733333.34        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.00        0.0   \n",
       "2        0.0        0.0        0.0  5500000.0        0.00        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.00        0.0   \n",
       "4  1180000.0        0.0        0.0        0.0        0.00        0.0   \n",
       "\n",
       "    963a49cdc  26fc93eb7  1931ccfdd  703885424  70feb1494  491b9ee45  \\\n",
       "0  13200000.0  3205000.0  2000000.0        0.0  1200000.0        0.0   \n",
       "1         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2  12000000.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   23310aa6f  e176a204a  6619d81fc  1db387535  fc99f9426  91f701ba2  \\\n",
       "0        0.0        0.0   400000.0        0.0        0.0  5000000.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   0572565c2  190db8488  adb64ff71  c47340d97  c5a231d81  0ff32eb98  \n",
       "0   400000.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "4        0.0        0.0        0.0  8000000.0        0.0        0.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.concat([train[[\"ID\", \"target\"] + cols], test[[\"ID\", \"target\"]+ cols]]).reset_index(drop=True)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main calculation for leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lag 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53801/53801 [06:13<00:00, 144.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lag 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53801/53801 [06:06<00:00, 146.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lag 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53801/53801 [05:55<00:00, 151.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lag 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53801/53801 [05:55<00:00, 151.52it/s]\n"
     ]
    }
   ],
   "source": [
    "all_df = get_all_leak(all_df, cols=cols, nlags=NLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we join both train and test sets with all_df leaky columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>leaked_target_0</th>\n",
       "      <th>leaked_target_1</th>\n",
       "      <th>leaked_target_2</th>\n",
       "      <th>leaked_target_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2800000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>164000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>979000.0</td>\n",
       "      <td>979000.0</td>\n",
       "      <td>979000.0</td>\n",
       "      <td>979000.0</td>\n",
       "      <td>979000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>460000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  leaked_target_0  leaked_target_1  leaked_target_2  \\\n",
       "0  38000000.0       38000000.0       38000000.0       38000000.0   \n",
       "1    600000.0         600000.0              0.0              0.0   \n",
       "2  10000000.0              0.0              0.0              0.0   \n",
       "3   2000000.0              0.0              0.0              0.0   \n",
       "4  14400000.0              0.0              0.0              0.0   \n",
       "5   2800000.0              0.0              0.0              0.0   \n",
       "6    164000.0              0.0              0.0              0.0   \n",
       "7    600000.0         600000.0              0.0              0.0   \n",
       "8    979000.0         979000.0         979000.0         979000.0   \n",
       "9    460000.0              0.0              0.0              0.0   \n",
       "\n",
       "   leaked_target_3  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "5        2800000.0  \n",
       "6         164000.0  \n",
       "7              0.0  \n",
       "8         979000.0  \n",
       "9              0.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaky_cols = [\"leaked_target_\"+str(i) for i in range(NLAGS)]\n",
    "train = train.join(all_df.set_index(\"ID\")[leaky_cols], on=\"ID\", how=\"left\")\n",
    "test = test.join(all_df.set_index(\"ID\")[leaky_cols], on=\"ID\", how=\"left\")\n",
    "train[[\"target\"]+leaky_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We calculate the mean for non-zero columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"nz_mean\"] = train[all_cols].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)\n",
    "test[\"nz_mean\"] = test[all_cols].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the first lag and recursivelly fill zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leak values found in train and test  2566 5479\n",
      "% of correct leaks values in train  0.992985190959\n"
     ]
    }
   ],
   "source": [
    "train[\"compiled_leak\"] = 0\n",
    "test[\"compiled_leak\"] = 0\n",
    "for i in range(NLAGS):\n",
    "    train.loc[train[\"compiled_leak\"] == 0, \"compiled_leak\"] = train.loc[train[\"compiled_leak\"] == 0, \"leaked_target_\"+str(i)]\n",
    "    test.loc[test[\"compiled_leak\"] == 0, \"compiled_leak\"] = test.loc[test[\"compiled_leak\"] == 0, \"leaked_target_\"+str(i)]\n",
    "    \n",
    "print(\"Leak values found in train and test \", sum(train[\"compiled_leak\"] > 0), sum(test[\"compiled_leak\"] > 0))\n",
    "print(\"% of correct leaks values in train \", sum(train[\"compiled_leak\"] == train[\"target\"])/sum(train[\"compiled_leak\"] > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace with the non-zeros mean the compiled leaks equal with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0400531239504043"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train[\"compiled_leak\"] == 0, \"compiled_leak\"] = train.loc[train[\"compiled_leak\"] == 0, \"nz_mean\"]\n",
    "test.loc[test[\"compiled_leak\"] == 0, \"compiled_leak\"] = test.loc[test[\"compiled_leak\"] == 0, \"nz_mean\"]\n",
    "np.sqrt(mean_squared_error(y, np.log1p(train[\"compiled_leak\"]).fillna(14.49)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1 = test[[\"ID\"]]\n",
    "sub1[\"target\"] = test[\"compiled_leak\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#0\"><font size=\"1\">Go to top</font></a>\n",
    "\n",
    "\n",
    "# <a id=\"5\">Build a model</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_KFOLDS  = 5\n",
    "NFOLDS = 5 #folds number for CV\n",
    "MAX_ROUNDS = 3000 #lgb iterations\n",
    "EARLY_STOP = 100 #lgb early stop \n",
    "VERBOSE_EVAL = 200 #Print out metric result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH+\"train.csv\")\n",
    "test = pd.read_csv(PATH+\"test.csv\")\n",
    "all_cols = [c for c in train.columns if c not in ['ID', 'target']]\n",
    "leak_col = []\n",
    "for c in all_cols:\n",
    "    leak1 = np.sum((train[c]==train['target']).astype(int))\n",
    "    leak2 = np.sum((((train[c] - train['target']) / train['target']) < 0.05).astype(int))\n",
    "    if leak1 > 30 and leak2 > 3500:\n",
    "        leak_col.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leak columns:  51\n"
     ]
    }
   ],
   "source": [
    "print('Leak columns: ',len(leak_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leak columns:  ['20aa07010', '87ffda550', '963a49cdc', '63c094ba4', '26fc93eb7', '0572565c2', '66ace2992', 'fb49e4212', '6619d81fc', '6eef030c1', 'fc99f9426', '1c71183bb', 'df838756c', 'b43a7cfd5', '024c577b9', '2ec5b290f', '44d5b820f', '0ff32eb98', '58e056e12', '241f0f867', '1931ccfdd', '58e2e02e6', '9fd594eec', 'fb0f5dbfe', 'd5fa73ead', 'f6eba969e', '91f701ba2', '8e4d0fe45', '703885424', '6c5c8869c', '2e103d632', '122c135ed', 'eeb9cd3aa', '324921c7b', '58232a6fb', '491b9ee45', 'd6bb78916', '70feb1494', 'adb64ff71', '62e59a501', '15ace8c9f', '5c6487af1', 'f190486d6', 'f74e8f13d', 'c5a231d81', 'e176a204a', '1702b5bf0', '190db8488', 'c47340d97', '6df033973', '23310aa6f']\n"
     ]
    }
   ],
   "source": [
    "print('Leak columns: ',leak_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = list(leak_col)\n",
    "train_lk = train[col +  ['ID', 'target']]\n",
    "test_lk = test[col +  ['ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in [train_lk, test_lk]:\n",
    "    df[\"nz_mean\"] = df[col].apply(lambda x: x[x!=0].mean(), axis=1)\n",
    "    df[\"nz_max\"] = df[col].apply(lambda x: x[x!=0].max(), axis=1)\n",
    "    df[\"nz_min\"] = df[col].apply(lambda x: x[x!=0].min(), axis=1)\n",
    "    df[\"ez\"] = df[col].apply(lambda x: len(x[x==0]), axis=1)\n",
    "    df[\"mean\"] = df[col].apply(lambda x: x.mean(), axis=1)\n",
    "    df[\"max\"] = df[col].apply(lambda x: x.max(), axis=1)\n",
    "    df[\"min\"] = df[col].apply(lambda x: x.min(), axis=1)\n",
    "    df[\"kurtosis\"] = df[col].apply(lambda x: x.kurtosis(), axis=1)\n",
    "col += ['nz_mean', 'nz_max', 'nz_min', 'ez', 'mean', 'max', 'min', 'kurtosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2, 100):\n",
    "    train_lk['index'+str(i)] = ((train_lk.index + 2) % i == 0).astype(int)\n",
    "    test_lk['index'+str(i)] = ((test_lk.index + 2) % i == 0).astype(int)\n",
    "    col.append('index'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge test_lk with prepared sub1 = test[ID, target] calculated before by exploiting the leal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_lk = pd.merge(test_lk, sub1, how='left', on='ID',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace zeros with NAs in both train_lk and test_lk and merge train_lk with test_lk in train_lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, vstack\n",
    "train_lk = train_lk.replace(0, np.nan)\n",
    "test_lk = test_lk.replace(0, np.nan)\n",
    "train_lk = pd.concat((train_lk, test_lk), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the lgb model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.07982\n",
      "[400]\tvalid_0's rmse: 1.0779\n",
      "Early stopping, best iteration is:\n",
      "[441]\tvalid_0's rmse: 1.07763\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.05267\n",
      "[400]\tvalid_0's rmse: 1.05184\n",
      "[600]\tvalid_0's rmse: 1.05228\n",
      "Early stopping, best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.05174\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.06287\n",
      "[400]\tvalid_0's rmse: 1.0613\n",
      "[600]\tvalid_0's rmse: 1.06076\n",
      "Early stopping, best iteration is:\n",
      "[605]\tvalid_0's rmse: 1.06072\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.02674\n",
      "[400]\tvalid_0's rmse: 1.02601\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid_0's rmse: 1.02583\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.05781\n",
      "[400]\tvalid_0's rmse: 1.05644\n",
      "Early stopping, best iteration is:\n",
      "[422]\tvalid_0's rmse: 1.05633\n"
     ]
    }
   ],
   "source": [
    "test_lk['target'] = 0.0\n",
    "folds = NFOLDS\n",
    "for fold in range(folds):\n",
    "    x1, x2, y1, y2 = model_selection.train_test_split(train_lk[col], \n",
    "                                                      np.log1p(train_lk.target.values), \n",
    "                                                      test_size=0.20, \n",
    "                                                      random_state=fold)\n",
    "    params = {'learning_rate': 0.02,\n",
    "              'max_depth': 7, \n",
    "              'boosting': 'gbdt', \n",
    "              'objective': 'regression', \n",
    "              'metric': 'rmse', \n",
    "              'is_training_metric': True, \n",
    "              'feature_fraction': 0.9, \n",
    "              'bagging_fraction': 0.8, \n",
    "              'bagging_freq': 5, \n",
    "              'seed':fold}\n",
    "    model = lgb.train(params, \n",
    "                      lgb.Dataset(x1, label=y1), \n",
    "                      MAX_ROUNDS, \n",
    "                      lgb.Dataset(x2, label=y2), \n",
    "                      verbose_eval=VERBOSE_EVAL, \n",
    "                      early_stopping_rounds=EARLY_STOP)\n",
    "    test_lk['target'] += np.expm1(model.predict(test_lk[col], \n",
    "                                num_iteration=model.best_iteration))\n",
    "test_lk['target'] /= folds\n",
    "sub1 = test_lk[['ID', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#0\"><font size=\"1\">Go to top</font></a>\n",
    "\n",
    "# <a id=\"6\">Average and submission</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "test_lk[['ID', 'target']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <a id=\"7\">References</a>  \n",
    "\n",
    "\n",
    "[1] <a href=\"https://www.kaggle.com/ogrellier\">olivier</a>, <a href=\"https://www.kaggle.com/ogrellier/santander-46-features\">Santander_46_features</a>   \n",
    "[2] <a href=\"https://www.kaggle.com/the1owl\">the1owl</a>, <a href=\"https://www.kaggle.com/the1owl/love-is-the-answer\">Love is the answer</a>   \n",
    "[3] <a href=\"https://www.kaggle.com/titericz\">Giba</a>, <a href=\"https://www.kaggle.com/titericz/the-property-by-giba\">The Property of Giba</a>   \n",
    "[4] <a href=\"https://www.kaggle.com/tezdhar\">Mohsin Hasan</a>, <a href=\"https://www.kaggle.com/tezdhar/breaking-lb-fresh-start\">Breaking LB - Fresh Start</a>   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
