{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Novel Coronavirus 2019-nCoV Data Preprocessing</h1>\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This Notebook only performs data preprocessing on the dataset with daily updates of coronavirus information.\n",
    "\n",
    "We will perform the following operations:\n",
    "* Check missing data; perform missing data imputation, if needed;\n",
    "* Check last update of the daily data;\n",
    "* Check multiple country names; fix the multiple country names, where needed;\n",
    "* Check multiple province/state;\n",
    "* Check if a country/region appears as well as province/state; \n",
    "* Deep-dive in the case of US states, cities, counties and unidentified places.\n",
    "* Export curated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "data_df = pd.read_csv(\"..//input//novel-corona-virus-2019-dataset//covid_19_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glimpse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: rows: 4935, cols: 8\n",
      "Data columns: ['SNo', 'ObservationDate', 'Province/State', 'Country/Region', 'Last Update', 'Confirmed', 'Deaths', 'Recovered']\n",
      "Days: 50 (01/22/2020 : 03/11/20)\n",
      "Country/Region: 128\n",
      "Province/State: 251\n",
      "Confirmed all: 87141\n",
      "Recovered all: 62073\n",
      "Deaths all: 3289\n",
      "Diagnosis: days since last update: 3 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Data: rows: {data_df.shape[0]}, cols: {data_df.shape[1]}\")\n",
    "print(f\"Data columns: {list(data_df.columns)}\")\n",
    "\n",
    "print(f\"Days: {data_df.ObservationDate.nunique()} ({data_df.ObservationDate.min()} : {data_df.ObservationDate.max()})\")\n",
    "print(f\"Country/Region: {data_df['Country/Region'].nunique()}\")\n",
    "print(f\"Province/State: {data_df['Province/State'].nunique()}\")\n",
    "print(f\"Confirmed all: {sum(data_df.groupby(['Province/State'])['Confirmed'].max())}\")\n",
    "print(f\"Recovered all: {sum(data_df.loc[~data_df.Recovered.isna()].groupby(['Province/State'])['Recovered'].max())}\")\n",
    "print(f\"Deaths all: {sum(data_df.loc[~data_df.Deaths.isna()].groupby(['Province/State'])['Deaths'].max())}\")\n",
    "\n",
    "print(f\"Diagnosis: days since last update: {(dt.datetime.now() - dt.datetime.strptime(data_df.ObservationDate.max(), '%m/%d/%y')).days} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: the dataset was not updates since few days ago (time to last run this Notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>ObservationDate</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SNo ObservationDate Province/State  Country/Region      Last Update  \\\n",
       "0    1      01/22/2020          Anhui  Mainland China  1/22/2020 17:00   \n",
       "1    2      01/22/2020        Beijing  Mainland China  1/22/2020 17:00   \n",
       "2    3      01/22/2020      Chongqing  Mainland China  1/22/2020 17:00   \n",
       "3    4      01/22/2020         Fujian  Mainland China  1/22/2020 17:00   \n",
       "4    5      01/22/2020          Gansu  Mainland China  1/22/2020 17:00   \n",
       "\n",
       "   Confirmed  Deaths  Recovered  \n",
       "0          1       0          0  \n",
       "1         14       0          0  \n",
       "2          6       0          0  \n",
       "3          1       0          0  \n",
       "4          0       0          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4935 entries, 0 to 4934\n",
      "Data columns (total 8 columns):\n",
      "SNo                4935 non-null int64\n",
      "ObservationDate    4935 non-null object\n",
      "Province/State     3120 non-null object\n",
      "Country/Region     4935 non-null object\n",
      "Last Update        4935 non-null object\n",
      "Confirmed          4935 non-null int64\n",
      "Deaths             4935 non-null int64\n",
      "Recovered          4935 non-null int64\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 308.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing data other than `Province/Region` - which makes sense, since for some of the Countries/Regions there is only Country/Region level data available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check multiple countries names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Azerbaijan', \"('St. Martin',)\", 'Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Argentina', 'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahrain', 'Bangladesh', 'Belarus', 'Belgium', 'Bhutan', 'Bolivia', 'Bosnia and Herzegovina', 'Brazil', 'Brunei', 'Bulgaria', 'Burkina Faso', 'Cambodia', 'Cameroon', 'Canada', 'Channel Islands', 'Chile', 'Colombia', 'Congo (Kinshasa)', 'Costa Rica', 'Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Dominican Republic', 'Ecuador', 'Egypt', 'Estonia', 'Faroe Islands', 'Finland', 'France', 'French Guiana', 'Georgia', 'Germany', 'Gibraltar', 'Greece', 'Holy See', 'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy', 'Ivory Coast', 'Jamaica', 'Japan', 'Jordan', 'Kuwait', 'Latvia', 'Lebanon', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macau', 'Mainland China', 'Malaysia', 'Maldives', 'Malta', 'Martinique', 'Mexico', 'Moldova', 'Monaco', 'Mongolia', 'Morocco', 'Nepal', 'Netherlands', 'New Zealand', 'Nigeria', 'North Ireland', 'North Macedonia', 'Norway', 'Oman', 'Others', 'Pakistan', 'Palestine', 'Panama', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Qatar', 'Republic of Ireland', 'Reunion', 'Romania', 'Russia', 'Saint Barthelemy', 'San Marino', 'Saudi Arabia', 'Senegal', 'Serbia', 'Singapore', 'Slovakia', 'Slovenia', 'South Africa', 'South Korea', 'Spain', 'Sri Lanka', 'St. Martin', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand', 'Togo', 'Tunisia', 'Turkey', 'UK', 'US', 'Ukraine', 'United Arab Emirates', 'Vatican City', 'Vietnam', 'occupied Palestinian territory']\n"
     ]
    }
   ],
   "source": [
    "country_sorted = list(data_df['Country/Region'].unique())\n",
    "country_sorted.sort()\n",
    "print(country_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Comment</font>: we can observe that there are few countries with duplicate name, as following:\n",
    "\n",
    "* ` Azerbaijan` & `Azerbaijan`;\n",
    "* `Holly See` & `Vatican City`;\n",
    "* `Ireland` & `Republic of Ireland`;\n",
    "* `St. Martin` & `('St. Martin',)`.\n",
    "\n",
    "For `UK` & `North Ireland` we will need a clarification, since theoretically `North Ireland` is a part of `UK`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix duplicated countries names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df['Country/Region']=='Holy See', 'Country/Region'] = 'Vatican City'\n",
    "data_df.loc[data_df['Country/Region']==' Azerbaijan', 'Country/Region'] = 'Azerbaijan'\n",
    "data_df.loc[data_df['Country/Region']=='Republic of Ireland', 'Country/Region'] = 'Ireland'\n",
    "data_df.loc[data_df['Country/Region']==\"('St. Martin',)\", 'Country/Region'] = 'St. Martin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check duplicate Province/State names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Montreal, QC', ' Norfolk County, MA', 'Alameda County, CA', 'Alaska', 'Alberta', 'Anhui', 'Arizona', 'Arkansas', 'Ashland, NE', 'Bavaria', 'Beijing', 'Bennington County, VT', 'Bergen County, NJ', 'Berkeley, CA', 'Berkshire County, MA', 'Boston, MA', 'British Columbia', 'Broward County, FL', 'Calgary, Alberta', 'California', 'Carver County, MN', 'Channel Islands', 'Charleston County, SC', 'Charlotte County, FL', 'Chatham County, NC', 'Cherokee County, GA', 'Chicago', 'Chicago, IL', 'Chongqing', 'Clark County, NV', 'Clark County, WA', 'Cobb County, GA', 'Collin County, TX', 'Colorado', 'Connecticut', 'Contra Costa County, CA', 'Cook County, IL', 'Cruise Ship', 'Davidson County, TN', 'Davis County, UT', 'Delaware', 'Delaware County, PA', 'Denmark', 'Denver County, CO', 'Diamond Princess cruise ship', 'District of Columbia', 'Douglas County, CO', 'Douglas County, NE', 'Douglas County, OR', 'Edmonton, Alberta', 'El Paso County, CO', 'Fairfax County, VA', 'Fairfield County, CT', 'Faroe Islands', 'Fayette County, KY', 'Florida', 'Floyd County, GA', 'Fort Bend County, TX', 'France', 'Fresno County, CA', 'From Diamond Princess', 'Fujian', 'Fulton County, GA', 'Gansu', 'Georgia', 'Gibraltar', 'Grafton County, NH', 'Grand Princess', 'Grand Princess Cruise Ship', 'Grant County, WA', 'Guangdong', 'Guangxi', 'Guizhou', 'Hainan', 'Harford County, MD', 'Harris County, TX', 'Harrison County, KY', 'Hawaii', 'Hebei', 'Heilongjiang', 'Henan', 'Hendricks County, IN', 'Hillsborough, FL', 'Hong Kong', 'Honolulu County, HI', 'Hubei', 'Hudson County, NJ', 'Humboldt County, CA', 'Hunan', 'Idaho', 'Illinois', 'Indiana', 'Inner Mongolia', 'Iowa', 'Jackson County, OR ', 'Jefferson County, KY', 'Jefferson County, WA', 'Jefferson Parish, LA', 'Jiangsu', 'Jiangxi', 'Jilin', 'Johnson County, IA', 'Johnson County, KS', 'Kansas', 'Kentucky', 'Kershaw County, SC', 'King County, WA', 'Kittitas County, WA', 'Klamath County, OR', 'Lackland, TX', 'Lackland, TX (From Diamond Princess)', 'Lee County, FL', 'Liaoning', 'London, ON', 'Los Angeles, CA', 'Louisiana', 'Macau', 'Madera County, CA', 'Madison, WI', 'Maine', 'Manatee County, FL', 'Maricopa County, AZ', 'Marion County, IN', 'Marion County, OR', 'Maryland', 'Massachusetts', 'Michigan', 'Middlesex County, MA', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Montgomery County, MD', 'Montgomery County, PA', 'Montgomery County, TX', 'Nassau County, NY', 'Nebraska', 'Nevada', 'New Brunswick', 'New Hampshire', 'New Jersey', 'New Mexico', 'New South Wales', 'New York', 'New York City, NY', 'New York County, NY', 'Ningxia', 'None', 'Norfolk County, MA', 'North Carolina', 'North Dakota', 'Northern Territory', 'Norwell County, MA', 'Ohio', 'Okaloosa County, FL', 'Oklahoma', 'Omaha, NE (From Diamond Princess)', 'Ontario', 'Orange County, CA', 'Orange, CA', 'Oregon', 'Pennsylvania', 'Pierce County, WA', 'Pinal County, AZ', 'Placer County, CA', 'Plymouth County, MA', 'Polk County, GA', 'Portland, OR', 'Providence County, RI', 'Providence, RI', 'Qinghai', 'Quebec', 'Queens County, NY', 'Queensland', 'Ramsey County, MN', 'Rhode Island', 'Riverside County, CA', 'Rockingham County, NH', 'Rockland County, NY', 'Sacramento County, CA', 'Saint Barthelemy', 'San Antonio, TX', 'San Benito, CA', 'San Diego County, CA', 'San Francisco County, CA', 'San Mateo, CA', 'Santa Clara County, CA', 'Santa Clara, CA', 'Santa Cruz County, CA', 'Santa Rosa County, FL', 'Sarasota, FL', 'Saratoga County, NY', 'Seattle, WA', 'Shaanxi', 'Shandong', 'Shanghai', 'Shanxi', 'Shasta County, CA', 'Shelby County, TN', 'Sichuan', 'Snohomish County, WA', 'Sonoma County, CA', 'South Australia', 'South Carolina', 'South Dakota', 'Spartanburg County, SC', 'Spokane County, WA', 'St Martin', 'St. Louis County, MO', 'Suffolk County, MA', 'Suffolk County, NY', 'Summit County, CO', 'Taiwan', 'Tasmania', 'Tempe, AZ', 'Tennessee', 'Texas', 'Tianjin', 'Tibet', 'Toronto, ON', 'Travis, CA', 'Travis, CA (From Diamond Princess)', 'Tulsa County, OK', 'UK', 'Ulster County, NY', 'Umatilla, OR', 'Unassigned Location (From Diamond Princess)', 'Unassigned Location, VT', 'Unassigned Location, WA', 'Unknown Location, MA', 'Utah', 'Vermont', 'Victoria', 'Virginia', 'Volusia County, FL', 'Wake County, NC', 'Washington', 'Washington County, OR', 'Washington, D.C.', 'Washoe County, NV', 'Wayne County, PA', 'West Virginia', 'Westchester County, NY', 'Western Australia', 'Williamson County, TN', 'Wisconsin', 'Wyoming', 'Xinjiang', 'Yolo County, CA', 'Yunnan', 'Zhejiang']\n"
     ]
    }
   ],
   "source": [
    "province_sorted = list(data_df.loc[~data_df['Province/State'].isna(), 'Province/State'].unique())\n",
    "province_sorted.sort()\n",
    "print(province_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Comment</font>: we can observe that there are few provinces with duplicate name or, for US - data at both county level and at state level & China with both province and independent territories. Here we show just few examples:\n",
    "\n",
    "* ' Norfolk County, MA' & 'Norfolk County, MA' - duplicate county name;\n",
    "*  'Providence County, RI' &  'Providence, RI' - duplicate county name from US;\n",
    "* 'France' - country name;\n",
    "* 'Washington' & 'Washington D.C.' & 'District of Columbia' - duplicate state name?;\n",
    "* 'Clark County, W' & 'Washington' (state)?\n",
    "* 'New York', 'New York City, NY', 'New York County, NY - possible duplicate for NYC?  \n",
    "* 'King County, WA', 'Kittitas County, WA but also Washington (state)?\n",
    "\n",
    "There are multiple attributions of `None` or `Unassigned Location`: `Unassigned Location (From Diamond Princess)`, `Unassigned Location, VT`, `Unassigned Location, WA`, `Unknown Location, MA`.\n",
    "\n",
    "There are multiple mentions of `from Diamond Princess`. Let's list them as well:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diamond Princess cruise ship', 'From Diamond Princess', 'Lackland, TX (From Diamond Princess)', 'Omaha, NE (From Diamond Princess)', 'Travis, CA (From Diamond Princess)', 'Unassigned Location (From Diamond Princess)']\n"
     ]
    }
   ],
   "source": [
    "diamond_list = list(data_df.loc[data_df['Province/State'].str.contains(\"Diamond\", na=False), 'Province/State'].unique())\n",
    "diamond_list.sort()\n",
    "print(diamond_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Country/Region & Province/State intersection\n",
    "\n",
    "\n",
    "We check now if a territory is marked both as a Country/Region and as a Province/State."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Taiwan', 'Hong Kong', 'Faroe Islands', 'Denmark', 'Georgia', 'France', 'Channel Islands', 'Saint Barthelemy', 'UK', 'Gibraltar', 'Macau'}\n"
     ]
    }
   ],
   "source": [
    "province_ = list(data_df.loc[~data_df['Province/State'].isna(), 'Province/State'].unique())\n",
    "country_ = list(data_df['Country/Region'].unique())\n",
    "\n",
    "common_province_country = set(province_) & set(country_)\n",
    "print(common_province_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now the name of the country when the province is in the common list of provinces and countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taiwan ['Taiwan']\n",
      "Hong Kong ['Hong Kong', 'Mainland China']\n",
      "Faroe Islands ['Denmark']\n",
      "Denmark ['Denmark']\n",
      "Georgia ['US']\n",
      "France ['France']\n",
      "Channel Islands ['UK']\n",
      "Saint Barthelemy ['France']\n",
      "UK ['UK']\n",
      "Gibraltar ['UK']\n",
      "Macau ['Macau', 'Mainland China']\n"
     ]
    }
   ],
   "source": [
    "for province in list(common_province_country):\n",
    "    country_list = list(data_df.loc[data_df['Province/State']==province, 'Country/Region'].unique())\n",
    "    print(province, country_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the provinces and countries list should be interpreted as folllowing:\n",
    "\n",
    "\n",
    "* Macau, Hong Kong appears both as independent Countries and as part of Mainland China; this is not correct.\n",
    "* France & Saint Barthelemy appears as provinces of France. This is not correct because Saint Barthelemy appears as well as an independent state. It must probably be fixed by replacing Saint Barthelemy as part of France, where appears as independent Country.\n",
    "* UK, Gibraltar & Channel Islands appears both as countries and as part from UK. It should be corrected by setting Gibraltar * Channel Islands as part of UK where appears as independent state;\n",
    "* Faroe Islands appears both as a state and as a part of Denmark. Should be corrected by setting only as a Province/State;\n",
    "* Georgia is both a state in US and an independent country. This is not an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check US states & counties\n",
    "\n",
    "In US we have both data at state level and at county level.   \n",
    "This might mislead when building statistics since we do not know for example if the statistic for Washington (State) includes also the data from King County, WA (a county from Washington state where is also Seattle).  \n",
    "\n",
    "\n",
    "Let's check first the list of counties in US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Norfolk County, MA', 'Alameda County, CA', 'Bennington County, VT', 'Bergen County, NJ', 'Berkshire County, MA', 'Broward County, FL', 'Carver County, MN', 'Charleston County, SC', 'Charlotte County, FL', 'Chatham County, NC', 'Cherokee County, GA', 'Clark County, NV', 'Clark County, WA', 'Cobb County, GA', 'Collin County, TX', 'Contra Costa County, CA', 'Cook County, IL', 'Davidson County, TN', 'Davis County, UT', 'Delaware County, PA', 'Denver County, CO', 'Douglas County, CO', 'Douglas County, NE', 'Douglas County, OR', 'El Paso County, CO', 'Fairfax County, VA', 'Fairfield County, CT', 'Fayette County, KY', 'Floyd County, GA', 'Fort Bend County, TX', 'Fresno County, CA', 'Fulton County, GA', 'Grafton County, NH', 'Grant County, WA', 'Harford County, MD', 'Harris County, TX', 'Harrison County, KY', 'Hendricks County, IN', 'Honolulu County, HI', 'Hudson County, NJ', 'Humboldt County, CA', 'Jackson County, OR ', 'Jefferson County, KY', 'Jefferson County, WA', 'Johnson County, IA', 'Johnson County, KS', 'Kershaw County, SC', 'King County, WA', 'Kittitas County, WA', 'Klamath County, OR', 'Lee County, FL', 'Madera County, CA', 'Manatee County, FL', 'Maricopa County, AZ', 'Marion County, IN', 'Marion County, OR', 'Middlesex County, MA', 'Montgomery County, MD', 'Montgomery County, PA', 'Montgomery County, TX', 'Nassau County, NY', 'New York County, NY', 'Norfolk County, MA', 'Norwell County, MA', 'Okaloosa County, FL', 'Orange County, CA', 'Pierce County, WA', 'Pinal County, AZ', 'Placer County, CA', 'Plymouth County, MA', 'Polk County, GA', 'Providence County, RI', 'Queens County, NY', 'Ramsey County, MN', 'Riverside County, CA', 'Rockingham County, NH', 'Rockland County, NY', 'Sacramento County, CA', 'San Diego County, CA', 'San Francisco County, CA', 'Santa Clara County, CA', 'Santa Cruz County, CA', 'Santa Rosa County, FL', 'Saratoga County, NY', 'Shasta County, CA', 'Shelby County, TN', 'Snohomish County, WA', 'Sonoma County, CA', 'Spartanburg County, SC', 'Spokane County, WA', 'St. Louis County, MO', 'Suffolk County, MA', 'Suffolk County, NY', 'Summit County, CO', 'Tulsa County, OK', 'Ulster County, NY', 'Volusia County, FL', 'Wake County, NC', 'Washington County, OR', 'Washoe County, NV', 'Wayne County, PA', 'Westchester County, NY', 'Williamson County, TN', 'Yolo County, CA']\n"
     ]
    }
   ],
   "source": [
    "counties_us = list(data_df.loc[(~data_df['Province/State'].isna()) & \\\n",
    "                               data_df['Province/State'].str.contains(\"County,\", na=False) &\\\n",
    "                               (data_df['Country/Region']=='US'), 'Province/State'].unique())\n",
    "counties_us.sort()\n",
    "print(counties_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now also the list of locations that are not counties but are not states names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ashland, NE', 'Berkeley, CA', 'Boston, MA', 'Chicago, IL', 'Hillsborough, FL', 'Jefferson Parish, LA', 'Lackland, TX', 'Lackland, TX (From Diamond Princess)', 'Los Angeles, CA', 'Madison, WI', 'New York City, NY', 'Omaha, NE (From Diamond Princess)', 'Orange, CA', 'Portland, OR', 'Providence, RI', 'San Antonio, TX', 'San Benito, CA', 'San Mateo, CA', 'Santa Clara, CA', 'Sarasota, FL', 'Seattle, WA', 'Tempe, AZ', 'Travis, CA', 'Travis, CA (From Diamond Princess)', 'Umatilla, OR', 'Unassigned Location, VT', 'Unassigned Location, WA', 'Unknown Location, MA', 'Washington, D.C.']\n"
     ]
    }
   ],
   "source": [
    "cities_places_us = list(data_df.loc[(~data_df['Province/State'].isna()) & \\\n",
    "                               (~data_df['Province/State'].str.contains(\"County,\", na=False)) &\\\n",
    "                               (data_df['Province/State'].str.contains(\",\", na=False)) &\\\n",
    "                               (data_df['Country/Region']=='US'), 'Province/State'].unique())\n",
    "cities_places_us.sort()\n",
    "print(cities_places_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few entries are not actual places, as following: `Lackland, TX (From Diamond Princess)`, `Omaha, NE (From Diamond Princess)` `Unassigned Location, VT`, `Unassigned Location, WA`, `Unknown Location, MA`.\n",
    "\n",
    "Let's check now the states names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alaska', 'Arizona', 'Arkansas', 'California', 'Chicago', 'Colorado', 'Connecticut', 'Delaware', 'Diamond Princess cruise ship', 'District of Columbia', 'Florida', 'Georgia', 'Grand Princess', 'Grand Princess Cruise Ship', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Unassigned Location (From Diamond Princess)', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "states_us = list(data_df.loc[(~data_df['Province/State'].isna()) & \\\n",
    "                               (~data_df['Province/State'].str.contains(\"County,\", na=False)) &\\\n",
    "                               (~data_df['Province/State'].str.contains(\",\", na=False)) &\\\n",
    "                               (data_df['Country/Region']=='US'), 'Province/State'].unique())\n",
    "states_us.sort()\n",
    "print(states_us)\n",
    "print(len(states_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few items here that are not states: Chicago (city in Illinois), Grand Princess (Diamond Princess?), Unassigned Location (From Diamond Princess)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the data\n",
    "\n",
    "We will export the curated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\"covid_19_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
